# Natural Language Processing

## Prerequisites
- **Python**: Data structures, NumPy, Pandas, Matplotlib, Seaborn
- **Math**: Basic statistics and linear algebra (Optional)
- **Machine Learning**: Data preprocessing, train-test split, classification, regression, evaluation metrics, overfitting, underfitting

## LEVEL-1: ABCD of NLP

| Day | Topic | Description | Resources |
|-----|-------|-------------|-----------|
| **Day 1** | **Introduction to NLP** | History, applications, NLU and NLG | |
| | **Overview of the full NLP lifecycle** | Text preprocessing<br>Text Representation<br>NLP tasks (classification)<br>Evaluation Metrics | |
| | **Tools and libraries** | Scikit-learn, nltk, spacy | |
| **Day 2** | **Text Preprocessing** | Cleaning text data<br><br>i) Tokenization<br>ii) Stopwords<br>iii) Lemmatization/ Stemming<br>iv) Handling punctuations, emojis, special symbols | |
| | **Text Representation** | i) Bag of words(BoW)<br>ii) TF-IDF<br>iii) Basics of Word2Vec, GloVe | |
| | **NLP tasks** | Sentiment analysis<br><br>Spam detection | |
| **Day 3** | **NLP Exam-001 (onsite)** | Quiz + Code | |
| | **NLP Project-001 (7 days)** | ## Project topic and guideline ## | |

## LEVEL-2: Context Matters

| Day | Topic | Description | Resources |
|-----|-------|-------------|-----------|
| **Day 1** | **Introduction to Deep Learning** | History, applications in NLP,<br>Feed forward basics | |
| | **Word Embeddings** | Word2Vec, GloVe, FastText.<br>Visualization using PCA/t-SNE | |
| | **Tools and libraries** | Tensorflow / PyTorch, Keras, gensim | |
| **Day 2** | **Sequence Models** | i) RNN<br>ii) LSTM+BiLSTM<br>iii) GRU<br>iv) Sequence padding, masking | |
| **Day 3** | **Application** | i) Sentiment analysis using LSTM<br>ii) Named entity recognition(NER)<br>iii) Machine translation (simple seq2seq) | |
| **Day 4** | **NLP Exam-002 (onsite)** | Quiz + Code | |
| | **NLP Project-002 (7 days)** | ## Project topic and guideline ## | |

## LEVEL-3: Attention is All You Need

| Day | Topic | Description | Resources |
|-----|-------|-------------|-----------|
| **Day 1** | **Introduction to Transformers** | Self attention and encoder-decoder overview | |
| | **BERT, GPT overview** | Architecture and applications | |
| **Day 2** | **Transfer Learning in NLP** | How to fine tune a BERT model for a specific field (physics, medical, comedy etc) | |
| | **Fine tuning pre-trained models** | | |
| **Day 3** | **Text Generation and Summarization** | Text summarization with T5 | |
| | **Question answering** | Q&A with hugging face transformers | |
| **Day 4** | **Introduction to LLMs** | | |